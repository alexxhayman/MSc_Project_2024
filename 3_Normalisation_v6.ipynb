{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcce0803",
   "metadata": {},
   "source": [
    "Where we stand:\n",
    "\n",
    "1. JSON file converted to CSV\n",
    "2. Ratios added to CSV file\n",
    "\n",
    "Next Steps: \n",
    "\n",
    "1. Remove unwanted columns\n",
    "2. Treat missing values using median imputation\n",
    "3. Insert ratios\n",
    "4. Standerdise dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35fea0ce",
   "metadata": {},
   "source": [
    "# Filter out the columns we do not need any data from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c068aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Dataset saved to new csv file: primary_filtered_road_bikes_2020-2024.csv\n"
     ]
    }
   ],
   "source": [
    "# Primary Filter\n",
    "\n",
    "# Filtering out the columns (features) we don't need for analysis. \n",
    "# This is done by only including those columns required instead of dropping columns - \n",
    "# we don't need as they may change. \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def process_csv(input_file, output_file, columns_to_include):\n",
    "    # Load the CSV file into a DataFrame with only the specified columns\n",
    "    df = pd.read_csv(input_file, usecols=columns_to_include)\n",
    "    \n",
    "    # Save the modified DataFrame to a new CSV file\n",
    "    df.to_csv(output_file, index=False)\n",
    "\n",
    "# Replace with the names of columns you want to include\n",
    "columns_to_include = [\n",
    "    'name',\n",
    "    'id',\n",
    "    'url',\n",
    "    'subcategory',\n",
    "    'geometry.source.stackMM',\n",
    "    'geometry.source.reachMM',\n",
    "    'geometry.source.seatTubeLengthMM',\n",
    "    'geometry.source.seatTubeAngle',\n",
    "    'geometry.source.headTubeLengthMM',\n",
    "    'geometry.source.topTubeLengthMM',\n",
    "    'geometry.source.headTubeAngle',\n",
    "    'geometry.source.chainstayLengthMM',\n",
    "    'geometry.source.bottomBracketDropMM',\n",
    "    'geometry.source.wheelbaseMM',\n",
    "    'geometry.source.rakeMM',\n",
    "    'geometry.source.trailMM',\n",
    "    'geometry.computed.stackReachRatio',\n",
    "    'geometry.computed.bottomBracketHeightMM',\n",
    "    'geometry.computed.frontCenterMM',\n",
    "    'geometry.computed.rakeMM',\n",
    "    'geometry.computed.trailMM',\n",
    "    'geometry.source.bottomBracketHeightMM',\n",
    "    'geometry.source.frontCenterMM',\n",
    "    'geometry.computed.wheelbaseMM',\n",
    "    'geometry.computed.bottomBracketDropMM',\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "]\n",
    "\n",
    "# Enter Data:\n",
    "input_file = 'all_road_bikes_2020-2024.csv'\n",
    "output_file = 'primary_filtered_road_bikes_2020-2024.csv'\n",
    "\n",
    "process_csv(input_file, output_file, columns_to_include)\n",
    "\n",
    "print('Filtered Dataset saved to new csv file: primary_filtered_road_bikes_2020-2024.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a85f24",
   "metadata": {},
   "source": [
    "## Combine the primary and secondary columns into a single column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c946301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined dataset saved to new csv file: combined_road_bikes_2020-2024.csv\n"
     ]
    }
   ],
   "source": [
    "# Combining Trail, Rake, BB Height, BB Drop, Front Center and Wheelbase Columns. \n",
    "# There are 2 columns for each of these features. \n",
    "# There is a priority for each column if both contain values, otherwise defaults to one with value. \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def combine_columns(input_file, output_file):\n",
    "    # Load the CSV file into a DataFrame\n",
    "    df = pd.read_csv(input_file)\n",
    "    \n",
    "    # Define column pairs to check and fill missing values\n",
    "    column_pairs = {\n",
    "        'geometry.source.trailMM': 'geometry.computed.trailMM',\n",
    "        'geometry.source.rakeMM': 'geometry.computed.rakeMM',\n",
    "        'geometry.source.frontCenterMM': 'geometry.computed.frontCenterMM',\n",
    "        'geometry.source.bottomBracketDropMM': 'geometry.computed.bottomBracketDropMM',\n",
    "        'geometry.source.wheelbaseMM': 'geometry.computed.wheelbaseMM',\n",
    "        'geometry.computed.bottomBracketHeightMM': 'geometry.source.bottomBracketHeightMM'  # Handling as per your script logic\n",
    "    }\n",
    "\n",
    "    # Fill primary column with secondary column values if primary is empty\n",
    "    for primary, secondary in column_pairs.items():\n",
    "        if primary in df.columns and secondary in df.columns:\n",
    "            df[primary] = df[primary].fillna(df[secondary])\n",
    "        else:\n",
    "            print(f\"Warning: Missing one of the columns: {primary} or {secondary}\")\n",
    "\n",
    "    # Save the modified DataFrame to a new CSV file\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"Combined dataset saved to new csv file: {output_file}\")\n",
    "\n",
    "# Enter Data:\n",
    "input_file = 'primary_filtered_road_bikes_2020-2024.csv'\n",
    "output_file = 'combined_road_bikes_2020-2024.csv'\n",
    "\n",
    "combine_columns(input_file, output_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6521ce",
   "metadata": {},
   "source": [
    "## Filter out secondary column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df9963a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Dataset saved to new csv file: filtered_combined_road_bikes_2020-2024.csv\n"
     ]
    }
   ],
   "source": [
    "# Secondary Filter\n",
    "\n",
    "# Now that the 6 columns have been consolidated we can filter out the extra\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def process_csv(input_file, output_file, columns_to_include):\n",
    "    # Load the CSV file into a DataFrame with only the specified columns\n",
    "    df = pd.read_csv(input_file, usecols=columns_to_include)\n",
    "    \n",
    "    # Save the modified DataFrame to a new CSV file\n",
    "    df.to_csv(output_file, index=False)\n",
    "\n",
    "# Replace with the names of columns you want to include\n",
    "columns_to_include = [  \n",
    "    'subcategory', \n",
    "    'geometry.source.stackMM',\n",
    "    'geometry.source.reachMM',\n",
    "    'geometry.source.seatTubeLengthMM',\n",
    "    'geometry.source.topTubeLengthMM',\n",
    "    'geometry.source.seatTubeAngle',\n",
    "    'geometry.source.headTubeAngle',\n",
    "    'geometry.source.chainstayLengthMM',\n",
    "    'geometry.source.bottomBracketDropMM',\n",
    "    'geometry.source.wheelbaseMM',\n",
    "    'geometry.source.rakeMM',\n",
    "    'geometry.source.trailMM',\n",
    "    'geometry.computed.stackReachRatio',\n",
    "    'geometry.computed.bottomBracketHeightMM',\n",
    "    'geometry.source.frontCenterMM',\n",
    "]\n",
    "    \n",
    "\n",
    "\n",
    "# Enter Data:\n",
    "input_file = 'combined_road_bikes_2020-2024.csv'\n",
    "output_file = 'filtered_combined_road_bikes_2020-2024.csv'\n",
    "\n",
    "process_csv(input_file, output_file, columns_to_include)\n",
    "\n",
    "print('Filtered Dataset saved to new csv file: filtered_combined_road_bikes_2020-2024.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d905cb2d",
   "metadata": {},
   "source": [
    "# Impute Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f797eba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cleaned. Rows with more than 30.0% missing values removed.\n",
      "Cleaned data saved to imputed_road_bikes_2020-2024.csv\n",
      "Cleaned DataFrame:\n",
      "  subcategory  geometry.source.stackMM  geometry.source.reachMM  \\\n",
      "0      gravel                    548.0                    373.0   \n",
      "1      gravel                    558.0                    375.0   \n",
      "2      gravel                    572.0                    381.0   \n",
      "3      gravel                    588.0                    385.0   \n",
      "4      gravel                    601.0                    391.0   \n",
      "\n",
      "   geometry.source.topTubeLengthMM  geometry.source.seatTubeLengthMM  \\\n",
      "0                            530.0                             430.0   \n",
      "1                            540.0                             450.0   \n",
      "2                            550.0                             470.0   \n",
      "3                            565.0                             490.0   \n",
      "4                            575.0                             510.0   \n",
      "\n",
      "   geometry.source.seatTubeAngle  geometry.source.headTubeAngle  \\\n",
      "0                           74.0                           70.5   \n",
      "1                           73.5                           70.5   \n",
      "2                           73.5                           70.5   \n",
      "3                           73.0                           71.0   \n",
      "4                           73.0                           71.0   \n",
      "\n",
      "   geometry.source.chainstayLengthMM  geometry.source.bottomBracketDropMM  \\\n",
      "0                              430.0                                 70.0   \n",
      "1                              430.0                                 70.0   \n",
      "2                              430.0                                 70.0   \n",
      "3                              430.0                                 70.0   \n",
      "4                              430.0                                 70.0   \n",
      "\n",
      "   geometry.source.wheelbaseMM  geometry.source.rakeMM  \\\n",
      "0                       1020.0                    50.0   \n",
      "1                       1025.0                    50.0   \n",
      "2                       1036.0                    50.0   \n",
      "3                       1041.0                    50.0   \n",
      "4                       1051.0                    50.0   \n",
      "\n",
      "   geometry.source.trailMM  geometry.computed.stackReachRatio  \\\n",
      "0                     75.0                              1.469   \n",
      "1                     75.0                              1.488   \n",
      "2                     75.0                              1.501   \n",
      "3                     71.6                              1.527   \n",
      "4                     71.6                              1.537   \n",
      "\n",
      "   geometry.computed.bottomBracketHeightMM  geometry.source.frontCenterMM  \n",
      "0                                    279.0                          600.0  \n",
      "1                                    279.0                          605.0  \n",
      "2                                    279.0                          616.0  \n",
      "3                                    279.0                          621.0  \n",
      "4                                    279.0                          631.0  \n"
     ]
    }
   ],
   "source": [
    "# Remove rows that contain more than 30% empty fields\n",
    "# This is the threshold at which imputation will begin to introduce heavy bias. \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def remove_rows_with_missing_data(csv_file_path, threshold=0.30):\n",
    "    # Load the dataset from a CSV file\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "    \n",
    "    # Calculate the number of columns\n",
    "    total_columns = df.shape[1]\n",
    "    \n",
    "    # Calculate the maximum allowed missing values per row\n",
    "    max_allowed_missing = total_columns * threshold\n",
    "    \n",
    "    # Remove rows with missing values exceeding the threshold\n",
    "    # This keeps rows with at least (total_columns - max_allowed_missing) non-missing values\n",
    "    df_cleaned = df.dropna(thresh=total_columns - max_allowed_missing)\n",
    "    \n",
    "    # Save the cleaned dataset to a new CSV file\n",
    "    new_file_path = 'imputed_road_bikes_2020-2024.csv'\n",
    "    df_cleaned.to_csv(new_file_path, index=False)\n",
    "    \n",
    "    print(f\"Data cleaned. Rows with more than {threshold*100}% missing values removed.\")\n",
    "    print(f\"Cleaned data saved to {new_file_path}\")\n",
    "\n",
    "    return df_cleaned\n",
    "\n",
    "# Enter Data:\n",
    "if __name__ == \"__main__\":\n",
    "    # Path to your CSV file\n",
    "    csv_file_path = 'filtered_combined_road_bikes_2020-2024.csv'\n",
    "    cleaned_df = remove_rows_with_missing_data(csv_file_path)\n",
    "    print(\"Cleaned DataFrame:\")\n",
    "    print(cleaned_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a029c1e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data with median-imputed values has been saved to median_imputed_road_bikes_2020-2024.csv\n",
      "DataFrame with median-imputed values:\n",
      "  subcategory  geometry.source.stackMM  geometry.source.reachMM  \\\n",
      "0      gravel                    548.0                    373.0   \n",
      "1      gravel                    558.0                    375.0   \n",
      "2      gravel                    572.0                    381.0   \n",
      "3      gravel                    588.0                    385.0   \n",
      "4      gravel                    601.0                    391.0   \n",
      "\n",
      "   geometry.source.topTubeLengthMM  geometry.source.seatTubeLengthMM  \\\n",
      "0                            530.0                             430.0   \n",
      "1                            540.0                             450.0   \n",
      "2                            550.0                             470.0   \n",
      "3                            565.0                             490.0   \n",
      "4                            575.0                             510.0   \n",
      "\n",
      "   geometry.source.seatTubeAngle  geometry.source.headTubeAngle  \\\n",
      "0                           74.0                           70.5   \n",
      "1                           73.5                           70.5   \n",
      "2                           73.5                           70.5   \n",
      "3                           73.0                           71.0   \n",
      "4                           73.0                           71.0   \n",
      "\n",
      "   geometry.source.chainstayLengthMM  geometry.source.bottomBracketDropMM  \\\n",
      "0                              430.0                                 70.0   \n",
      "1                              430.0                                 70.0   \n",
      "2                              430.0                                 70.0   \n",
      "3                              430.0                                 70.0   \n",
      "4                              430.0                                 70.0   \n",
      "\n",
      "   geometry.source.wheelbaseMM  geometry.source.rakeMM  \\\n",
      "0                       1020.0                    50.0   \n",
      "1                       1025.0                    50.0   \n",
      "2                       1036.0                    50.0   \n",
      "3                       1041.0                    50.0   \n",
      "4                       1051.0                    50.0   \n",
      "\n",
      "   geometry.source.trailMM  geometry.computed.stackReachRatio  \\\n",
      "0                     75.0                              1.469   \n",
      "1                     75.0                              1.488   \n",
      "2                     75.0                              1.501   \n",
      "3                     71.6                              1.527   \n",
      "4                     71.6                              1.537   \n",
      "\n",
      "   geometry.computed.bottomBracketHeightMM  geometry.source.frontCenterMM  \n",
      "0                                    279.0                          600.0  \n",
      "1                                    279.0                          605.0  \n",
      "2                                    279.0                          616.0  \n",
      "3                                    279.0                          621.0  \n",
      "4                                    279.0                          631.0  \n"
     ]
    }
   ],
   "source": [
    "# Median imputation. \n",
    "# Now impute the rows that contained more than 30% empty values. \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def impute_missing_values_median(csv_file_path):\n",
    "    # Load the dataset from a CSV file\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "    \n",
    "    # List of columns to exclude from imputation (hard-coded)\n",
    "    exclude_columns = ['subcategory']  # Add more column names as needed\n",
    "    \n",
    "    # Separate the excluded columns and the rest of the data\n",
    "    id_and_other_excluded_columns = df[exclude_columns]\n",
    "    data_to_impute = df.drop(columns=exclude_columns)\n",
    "    \n",
    "    # Impute missing values using the median for each column\n",
    "    for column in data_to_impute.columns:\n",
    "        median_value = data_to_impute[column].median()\n",
    "        data_to_impute[column].fillna(median_value, inplace=True)\n",
    "    \n",
    "    # Reattach the excluded columns to the dataframe\n",
    "    for col in exclude_columns:\n",
    "        data_to_impute[col] = id_and_other_excluded_columns[col]\n",
    "    \n",
    "    # Ensure excluded columns are at the beginning of the dataframe\n",
    "    cols = exclude_columns + [col for col in data_to_impute.columns if col not in exclude_columns]\n",
    "    imputed_df = data_to_impute[cols]\n",
    "    \n",
    "    # Save the dataset with imputed values to a new CSV file\n",
    "    new_file_path = 'median_imputed_road_bikes_2020-2024.csv'\n",
    "    imputed_df.to_csv(new_file_path, index=False)\n",
    "    \n",
    "    print(f\"Data with median-imputed values has been saved to {new_file_path}\")\n",
    "    \n",
    "    return imputed_df\n",
    "\n",
    "# Enter Data:\n",
    "if __name__ == \"__main__\":\n",
    "    # Path to your CSV file\n",
    "    csv_file_path = 'imputed_road_bikes_2020-2024.csv'\n",
    "    df_imputed = impute_missing_values_median(csv_file_path)\n",
    "    print(\"DataFrame with median-imputed values:\")\n",
    "    print(df_imputed.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4806f1",
   "metadata": {},
   "source": [
    "# Prepare for Ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed189ceb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data with angles converted to radians has been saved to radians_median_imputed_road_bikes_2020-2024.csv\n",
      "Updated DataFrame:\n",
      "  subcategory  geometry.source.stackMM  geometry.source.reachMM  \\\n",
      "0      gravel                    548.0                    373.0   \n",
      "1      gravel                    558.0                    375.0   \n",
      "2      gravel                    572.0                    381.0   \n",
      "3      gravel                    588.0                    385.0   \n",
      "4      gravel                    601.0                    391.0   \n",
      "\n",
      "   geometry.source.topTubeLengthMM  geometry.source.seatTubeLengthMM  \\\n",
      "0                            530.0                             430.0   \n",
      "1                            540.0                             450.0   \n",
      "2                            550.0                             470.0   \n",
      "3                            565.0                             490.0   \n",
      "4                            575.0                             510.0   \n",
      "\n",
      "   geometry.source.chainstayLengthMM  geometry.source.bottomBracketDropMM  \\\n",
      "0                              430.0                                 70.0   \n",
      "1                              430.0                                 70.0   \n",
      "2                              430.0                                 70.0   \n",
      "3                              430.0                                 70.0   \n",
      "4                              430.0                                 70.0   \n",
      "\n",
      "   geometry.source.wheelbaseMM  geometry.source.rakeMM  \\\n",
      "0                       1020.0                    50.0   \n",
      "1                       1025.0                    50.0   \n",
      "2                       1036.0                    50.0   \n",
      "3                       1041.0                    50.0   \n",
      "4                       1051.0                    50.0   \n",
      "\n",
      "   geometry.source.trailMM  geometry.computed.stackReachRatio  \\\n",
      "0                     75.0                              1.469   \n",
      "1                     75.0                              1.488   \n",
      "2                     75.0                              1.501   \n",
      "3                     71.6                              1.527   \n",
      "4                     71.6                              1.537   \n",
      "\n",
      "   geometry.computed.bottomBracketHeightMM  geometry.source.frontCenterMM  \\\n",
      "0                                    279.0                          600.0   \n",
      "1                                    279.0                          605.0   \n",
      "2                                    279.0                          616.0   \n",
      "3                                    279.0                          621.0   \n",
      "4                                    279.0                          631.0   \n",
      "\n",
      "   geometry.source.headTubeAngle_radians  \\\n",
      "0                               1.230457   \n",
      "1                               1.230457   \n",
      "2                               1.230457   \n",
      "3                               1.239184   \n",
      "4                               1.239184   \n",
      "\n",
      "   geometry.source.seatTubeAngle_radians  \n",
      "0                               1.291544  \n",
      "1                               1.282817  \n",
      "2                               1.282817  \n",
      "3                               1.274090  \n",
      "4                               1.274090  \n"
     ]
    }
   ],
   "source": [
    "# Convert Angles to Radians for Formulas\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def convert_angles_to_radians(csv_file_path, angle_columns, new_file_name):\n",
    "    \"\"\"\n",
    "    Reads a DataFrame from a CSV file, converts specified angle columns from degrees to radians,\n",
    "    renames these columns to indicate the conversion, and saves the updated DataFrame to a new CSV file.\n",
    "\n",
    "    Parameters:\n",
    "        csv_file_path (str): The path to the CSV file to process.\n",
    "        angle_columns (list): A list of column names to convert from degrees to radians.\n",
    "        new_file_name (str): The name of the new CSV file to save.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with updated columns where angles are now in radians.\n",
    "    \"\"\"\n",
    "    # Load the dataset from a CSV file\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "    \n",
    "    # Track columns not found\n",
    "    columns_not_found = []\n",
    "\n",
    "    # Iterate over each column in the list of angle columns\n",
    "    for col in angle_columns:\n",
    "        if col in df.columns:\n",
    "            # Convert the column from degrees to radians and create a new column for it\n",
    "            df[col + '_radians'] = np.radians(df[col])\n",
    "        else:\n",
    "            columns_not_found.append(col)\n",
    "\n",
    "    # Drop the original angle columns after all conversions are done\n",
    "    df.drop(columns=angle_columns, inplace=True, errors='ignore')\n",
    "\n",
    "    # Provide feedback about missing columns\n",
    "    if columns_not_found:\n",
    "        print(f\"Warning: Columns not found in the DataFrame: {', '.join(columns_not_found)}\")\n",
    "\n",
    "    # Save the modified DataFrame to a CSV file\n",
    "    df.to_csv(new_file_name, index=False)\n",
    "    print(f\"Data with angles converted to radians has been saved to {new_file_name}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Enter Data:\n",
    "if __name__ == \"__main__\":\n",
    "    # Define the path to your CSV file\n",
    "    csv_file_path = 'median_imputed_road_bikes_2020-2024.csv'  # Replace with the actual path to your CSV file\n",
    "    \n",
    "    # Define the columns whose angles you want to convert\n",
    "    angle_columns = ['geometry.source.headTubeAngle', 'geometry.source.seatTubeAngle']  # Adjust column names as necessary\n",
    "\n",
    "    # Specify the name for the new file \n",
    "    new_file_name = 'radians_median_imputed_road_bikes_2020-2024.csv'\n",
    "    \n",
    "    # Perform the conversion and get the updated DataFrame\n",
    "    df_updated = convert_angles_to_radians(csv_file_path, angle_columns, new_file_name)\n",
    "    \n",
    "    # Print the updated DataFrame to verify changes\n",
    "    print(\"Updated DataFrame:\")\n",
    "    print(df_updated.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2845d464",
   "metadata": {},
   "source": [
    "# Calculate Ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28dacded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated CSV with ratios and indices saved to all_road_bikes_with_ratios_2020-2024.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the data\n",
    "file_path = 'radians_median_imputed_road_bikes_2020-2024.csv'  # Make sure to replace with the correct path\n",
    "bikes_data = pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "# List of columns to normalize (add or remove columns as needed)\n",
    "columns_to_normalize = ['geometry.source.chainstayLengthMM',\n",
    "                        'geometry.computed.bottomBracketHeightMM',\n",
    "                        'geometry.source.bottomBracketDropMM', \n",
    "                        'geometry.source.stackMM', \n",
    "                        'geometry.source.trailMM',\n",
    "                        'geometry.source.reachMM',\n",
    "                        'geometry.source.rakeMM',\n",
    "                        'geometry.source.wheelbaseMM']\n",
    "\n",
    "# Seat tube length as the reference column\n",
    "reference_column = 'geometry.source.seatTubeLengthMM'\n",
    "\n",
    "# Normalize the specified columns\n",
    "for column in columns_to_normalize:\n",
    "    normalized_column_name = f'normalized_{column}'  # Naming the new column\n",
    "    bikes_data[normalized_column_name] = bikes_data[column] / bikes_data[reference_column]\n",
    "\n",
    "\n",
    "    \n",
    "# Ratios\n",
    "bikes_data['SRR'] = bikes_data['geometry.source.stackMM'] / bikes_data['geometry.source.reachMM']\n",
    "bikes_data['AI'] = (bikes_data['geometry.source.reachMM'] * np.tan(np.radians(bikes_data['geometry.source.headTubeAngle_radians']))) / bikes_data['geometry.source.wheelbaseMM']\n",
    "bikes_data['CS/BBD'] = bikes_data['geometry.source.chainstayLengthMM'] / bikes_data['geometry.source.bottomBracketDropMM']\n",
    "bikes_data['ETT/S'] = bikes_data['geometry.source.topTubeLengthMM'] / bikes_data['geometry.source.stackMM']\n",
    "\n",
    "\n",
    "\n",
    "# New Ratios\n",
    "bikes_data['T/WB'] = bikes_data['geometry.source.trailMM'] / bikes_data['geometry.source.wheelbaseMM']\n",
    "bikes_data['HTA/Trail'] = bikes_data['geometry.source.headTubeAngle_radians'] / bikes_data['geometry.source.trailMM']\n",
    "bikes_data['CSL/STA'] = bikes_data['geometry.source.chainstayLengthMM'] / bikes_data['geometry.source.seatTubeAngle_radians']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Interactions\n",
    "bikes_data['BBH_CS_Interaction'] = bikes_data['geometry.computed.bottomBracketHeightMM'] * bikes_data['geometry.source.chainstayLengthMM']\n",
    "bikes_data['BBH_WB_Interaction'] = bikes_data['geometry.computed.bottomBracketHeightMM'] * bikes_data['geometry.source.wheelbaseMM']\n",
    "\n",
    "\n",
    "\n",
    "# Composite Indices\n",
    "\n",
    "bikes_data['Stability_Index'] = (\n",
    "    0.5 * bikes_data['geometry.computed.bottomBracketHeightMM'] +\n",
    "    0.3 * bikes_data['geometry.source.chainstayLengthMM'] +\n",
    "    0.2 * bikes_data['geometry.source.wheelbaseMM']\n",
    ")\n",
    "\n",
    "bikes_data['Handling_Index'] = (\n",
    "    0.5 * bikes_data['geometry.source.headTubeAngle_radians'] +\n",
    "    0.25 * bikes_data['geometry.source.trailMM'] +\n",
    "    0.25 * bikes_data['geometry.source.rakeMM']\n",
    ")\n",
    "\n",
    "bikes_data['Comfort_Index'] = (\n",
    "    0.5 * bikes_data['BBH_CS_Interaction'] +\n",
    "    0.3 * bikes_data['CS/BBD'] +\n",
    "    0.2 * bikes_data['ETT/S']\n",
    ")\n",
    "\n",
    "# Save the DataFrame if needed\n",
    "# bikes_data.to_csv('path_to_your_updated_data.csv', index=False)  # Uncomment this line and replace with your path\n",
    "\n",
    "# Use this updated dataset for further modeling and analysis\n",
    "\n",
    "\n",
    "# Handle potential division by zero and missing data\n",
    "bikes_data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Save the updated dataframe to a new CSV file\n",
    "new_file_path = 'all_road_bikes_with_ratios_2020-2024.csv'  # Replace with desired new file path\n",
    "bikes_data.to_csv(new_file_path, index=False)\n",
    "\n",
    "print(f\"Updated CSV with ratios and indices saved to {new_file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29dde93e",
   "metadata": {},
   "source": [
    "# Standardising the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b92c65ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File has been saved to std_all_road_bikes_with_ratios_2020-2024.csv\n"
     ]
    }
   ],
   "source": [
    "# This script handles missing values and then standardises the dataset\n",
    "\n",
    "# Standardise the dataset using z-normalisation.\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('all_road_bikes_with_ratios_2020-2024.csv')\n",
    "\n",
    "# Identify numerical columns (excluding any potential ID columns or categorical columns)\n",
    "numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Z-normalize the numerical columns\n",
    "df[numerical_cols] = scaler.fit_transform(df[numerical_cols])\n",
    "\n",
    "# Save the updated dataframe to a new CSV file\n",
    "df.to_csv('std_all_road_bikes_with_ratios_2020-2024.csv', index=False)\n",
    "\n",
    "# Print confirmation that the file has been saved\n",
    "print('File has been saved to std_all_road_bikes_with_ratios_2020-2024.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e90eca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Dataset saved to new csv file: std1_all_road_bikes_2020-2024.csv\n"
     ]
    }
   ],
   "source": [
    "# Secondary Filter\n",
    "\n",
    "# Now that the 6 columns have been consolidated we can filter out the extra\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def process_csv(input_file, output_file, columns_to_include):\n",
    "    # Load the CSV file into a DataFrame with only the specified columns\n",
    "    df = pd.read_csv(input_file, usecols=columns_to_include)\n",
    "    \n",
    "    # Save the modified DataFrame to a new CSV file\n",
    "    df.to_csv(output_file, index=False)\n",
    "\n",
    "# Replace with the names of columns you want to include\n",
    "columns_to_include = [\n",
    "    \n",
    "    'subcategory',\n",
    "    'geometry.source.headTubeAngle_radians',\n",
    "    'geometry.source.seatTubeAngle_radians',\n",
    "    'normalized_geometry.source.chainstayLengthMM',\n",
    "    'normalized_geometry.computed.bottomBracketHeightMM',\n",
    "    'normalized_geometry.source.bottomBracketDropMM',\n",
    "    'normalized_geometry.source.stackMM', \n",
    "    'normalized_geometry.source.trailMM', \n",
    "    'normalized_geometry.source.reachMM',\n",
    "    'normalized_geometry.source.rakeMM', \n",
    "    'normalized_geometry.source.wheelbaseMM',\n",
    "    'SRR', \n",
    "    'AI',\n",
    "    'CS/BBD',\n",
    "    'ETT/S', \n",
    "    'T/WB', \n",
    "    'HTA/Trail',\n",
    "    'CSL/STA', \n",
    "    'BBH_CS_Interaction',\n",
    "    'BBH_WB_Interaction',\n",
    "    'Stability_Index', \n",
    "    'Handling_Index', \n",
    "    'Comfort_Index'\n",
    "]\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "# Enter Data:\n",
    "input_file = 'std_all_road_bikes_with_ratios_2020-2024.csv'\n",
    "output_file = 'std1_all_road_bikes_with_ratios_2020-2024.csv'\n",
    "\n",
    "process_csv(input_file, output_file, columns_to_include)\n",
    "\n",
    "print('Filtered Dataset saved to new csv file: std1_all_road_bikes_2020-2024.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a572b088",
   "metadata": {},
   "source": [
    "# Convert Subcateogry to number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92de1e4b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data with 'subcategory' encoded saved to encoded_road_bikes_2020-2024.csv\n",
      "Subcategory encoding assignment:\n",
      "gravel: 0\n",
      "race: 1\n",
      "endurance: 2\n",
      "aero: 3\n",
      "triathlon: 4\n",
      "cyclocross: 5\n",
      "touring: 6\n",
      "general-road: 7\n",
      "track: 8\n",
      "Encoded DataFrame:\n",
      "   subcategory  geometry.source.headTubeAngle_radians  \\\n",
      "0            0                              -0.010837   \n",
      "1            0                              -0.010837   \n",
      "2            0                              -0.010837   \n",
      "3            0                              -0.010008   \n",
      "4            0                              -0.010008   \n",
      "\n",
      "   geometry.source.seatTubeAngle_radians  \\\n",
      "0                              -0.009802   \n",
      "1                              -0.010610   \n",
      "2                              -0.010610   \n",
      "3                              -0.011417   \n",
      "4                              -0.011417   \n",
      "\n",
      "   normalized_geometry.source.chainstayLengthMM  \\\n",
      "0                                      0.517623   \n",
      "1                                      0.382442   \n",
      "2                                      0.258766   \n",
      "3                                      0.145186   \n",
      "4                                      0.040514   \n",
      "\n",
      "   normalized_geometry.computed.bottomBracketHeightMM  \\\n",
      "0                                           0.443746    \n",
      "1                                           0.324696    \n",
      "2                                           0.215778    \n",
      "3                                           0.115751    \n",
      "4                                           0.023569    \n",
      "\n",
      "   normalized_geometry.source.bottomBracketDropMM  \\\n",
      "0                                        0.387924   \n",
      "1                                        0.273087   \n",
      "2                                        0.168024   \n",
      "3                                        0.071538   \n",
      "4                                       -0.017381   \n",
      "\n",
      "   normalized_geometry.source.stackMM  normalized_geometry.source.trailMM  \\\n",
      "0                            0.346592                            0.033659   \n",
      "1                            0.267951                            0.010191   \n",
      "2                            0.215448                           -0.011281   \n",
      "3                            0.176556                           -0.052006   \n",
      "4                            0.127275                           -0.069354   \n",
      "\n",
      "   normalized_geometry.source.reachMM  normalized_geometry.source.rakeMM  ...  \\\n",
      "0                            0.330800                           0.456985  ...   \n",
      "1                            0.217303                           0.349983  ...   \n",
      "2                            0.141786                           0.252087  ...   \n",
      "3                            0.058851                           0.162183  ...   \n",
      "4                           -0.004530                           0.079330  ...   \n",
      "\n",
      "     CS/BBD     ETT/S      T/WB  HTA/Trail   CSL/STA  BBH_CS_Interaction  \\\n",
      "0  0.008002 -0.039466 -0.083849  -0.032574 -0.065783             0.02618   \n",
      "1  0.008002 -0.037341 -0.085683  -0.032574 -0.065497             0.02618   \n",
      "2  0.008002 -0.059734 -0.089656  -0.032574 -0.065497             0.02618   \n",
      "3  0.008002 -0.062095 -0.108134  -0.027329 -0.065208             0.02618   \n",
      "4  0.008002 -0.077060 -0.111481  -0.027329 -0.065208             0.02618   \n",
      "\n",
      "   BBH_WB_Interaction  Stability_Index  Handling_Index  Comfort_Index  \n",
      "0            0.002424         0.042303       -0.032564       0.026179  \n",
      "1            0.007267         0.049974       -0.032564       0.026179  \n",
      "2            0.017922         0.066849       -0.032564       0.026179  \n",
      "3            0.022765         0.074519       -0.052045       0.026179  \n",
      "4            0.032451         0.089860       -0.052045       0.026179  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def encode_subcategory(csv_file_path, output_file_path):\n",
    "    \"\"\"\n",
    "    Reads a DataFrame from a CSV file, encodes the 'subcategory' column into numeric labels using a predefined mapping,\n",
    "    and saves the updated DataFrame to a new CSV file.\n",
    "\n",
    "    Parameters:\n",
    "        csv_file_path (str): The path to the CSV file to process.\n",
    "        output_file_path (str): The path where the modified CSV file should be saved.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with the 'subcategory' column encoded as integers.\n",
    "    \"\"\"\n",
    "    # Load the dataset from a CSV file\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "    \n",
    "    # Check if the 'subcategory' column exists in the DataFrame\n",
    "    if 'subcategory' in df.columns:\n",
    "        # Predefined mapping for subcategories\n",
    "        subcategory_mapping = {\n",
    "            'gravel': 0,\n",
    "            'race': 1,\n",
    "            'endurance': 2,\n",
    "            'aero': 3,\n",
    "            'triathlon': 4,\n",
    "            'cyclocross': 5,\n",
    "            'touring': 6,\n",
    "            'general-road': 7,\n",
    "            'track': 8\n",
    "        }\n",
    "        \n",
    "        # Encode the 'subcategory' column using the mapping\n",
    "        df['subcategory'] = df['subcategory'].map(subcategory_mapping)\n",
    "        \n",
    "        # Check for any subcategories that weren't in the mapping\n",
    "        if df['subcategory'].isna().any():\n",
    "            print(\"Warning: Some subcategories were not in the predefined mapping and have been encoded as NaN.\")\n",
    "        \n",
    "        # Save the modified DataFrame to the specified new CSV file\n",
    "        df.to_csv(output_file_path, index=False)\n",
    "        \n",
    "        print(f\"Data with 'subcategory' encoded saved to {output_file_path}\")\n",
    "        print(\"Subcategory encoding assignment:\")\n",
    "        for k, v in subcategory_mapping.items():\n",
    "            print(f\"{k}: {v}\")\n",
    "    else:\n",
    "        print(\"Error: 'subcategory' column not found in the DataFrame.\")\n",
    "\n",
    "    return df\n",
    "\n",
    "# Enter Data:\n",
    "if __name__ == \"__main__\":\n",
    "    csv_file_path = 'std1_all_road_bikes_with_ratios_2020-2024.csv'  # Replace with the actual path to your CSV file\n",
    "    output_file_path = 'encoded_road_bikes_2020-2024.csv'  # Specify the output file name\n",
    "    df_encoded = encode_subcategory(csv_file_path, output_file_path)\n",
    "    \n",
    "    # Optionally print the head of the updated DataFrame to verify the changes\n",
    "    print(\"Encoded DataFrame:\")\n",
    "    print(df_encoded.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99dd49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee5742b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269cab3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a8e21a7",
   "metadata": {},
   "source": [
    "# End of normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4801b54d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d656b9f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fac8db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ea56be98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['subcategory', 'geometry.source.stackMM', 'geometry.source.reachMM', 'geometry.source.topTubeLengthMM', 'geometry.source.seatTubeLengthMM', 'geometry.source.chainstayLengthMM', 'geometry.source.bottomBracketDropMM', 'geometry.source.wheelbaseMM', 'geometry.source.rakeMM', 'geometry.source.trailMM', 'geometry.computed.stackReachRatio', 'geometry.computed.bottomBracketHeightMM', 'geometry.source.frontCenterMM', 'geometry.source.headTubeAngle_radians', 'geometry.source.seatTubeAngle_radians', 'normalized_geometry.source.chainstayLengthMM', 'normalized_geometry.computed.bottomBracketHeightMM', 'normalized_geometry.source.bottomBracketDropMM', 'normalized_geometry.source.stackMM', 'normalized_geometry.source.trailMM', 'normalized_geometry.source.reachMM', 'normalized_geometry.source.rakeMM', 'normalized_geometry.source.wheelbaseMM', 'SRR', 'AI', 'CS/BBD', 'ETT/S', 'T/WB', 'HTA/Trail', 'CSL/STA', 'BBH_CS_Interaction', 'BBH_WB_Interaction', 'Stability_Index', 'Handling_Index', 'Comfort_Index']\n"
     ]
    }
   ],
   "source": [
    "# Use this script to Print out all the columns from your CSV file. \n",
    "# Change the path to file \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data from a CSV file\n",
    "bikes_data = pd.read_csv('all_road_bikes_with_ratios_2020-2024.csv')\n",
    "\n",
    "# Print the column names\n",
    "print(bikes_data.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183b034b",
   "metadata": {},
   "source": [
    "# Print DataFrame Statement Explained \n",
    "\n",
    "The `print(bikes_data.columns.tolist())` statement is used to display the column names of a pandas DataFrame. \n",
    "\n",
    "1. **`bikes_data`**: This is a variable that typically represents a pandas DataFrame. In your case, it would be the DataFrame that contains your bike data, which you would have loaded from a CSV file using pandas' `read_csv` function.\n",
    "\n",
    "2. **`.columns`**: This is an attribute of the DataFrame that holds an Index object containing the column labels of the DataFrame.\n",
    "\n",
    "3. **`.tolist()`**: This is a method called on the DataFrame's `.columns` attribute. The `Index` object (which `.columns` returns) has a method called `tolist()` that converts the index into a standard Python list containing the column names.\n",
    "\n",
    "4. **`print()`**: This is the standard Python function that outputs information to the console. When you wrap `bikes_data.columns.tolist()` inside a `print()` function, it prints the list of column names to the console.\n",
    "\n",
    "Here's how this all works in practice:\n",
    "- First, you load your data from a CSV file into the `bikes_data` DataFrame. This operation parses the CSV file and creates a DataFrame structure where the column headers in the CSV become the column labels in the DataFrame.\n",
    "- Then, using `bikes_data.columns.tolist()`, you retrieve these labels and convert them into a list.\n",
    "- Finally, by passing this list to the `print()` function, you can visually inspect the column names directly in your console or output window.\n",
    "\n",
    "This process is helpful for debugging and ensuring that you reference the correct column names in your code, especially when setting up data processing tasks like filtering, scaling, or any operations specific to certain columns. If there's a typo in the column name or if you're unsure about the exact naming, this output lets you quickly verify and correct the names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f06dd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7838f712",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
